---
title: "Experimental Design"
author: "Venukanan Subenthiran"
date: "2022-11-19"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#load("R_Studio_Global_Variables.RData")
```

# Experimental Design

## Splitting the Data into Training and Test Sets

```{r}

#install.packages("caTools")
library(caTools)



set.seed(123)

TrainTestData <- sample.split(Y = fraudTotal.db$is_fraud, SplitRatio = 0.7)
FD_Train <- fraudTotal.db[TrainTestData,]
FD_Test <- fraudTotal.db[!TrainTestData,]

#converting dob to numeric
FD_Train$dob <- as.numeric(FD_Train$dob)
FD_Test$dob <- as.numeric(FD_Test$dob)


#convertig trans_date_trans_time to numeric
FD_Train$trans_date_trans_time <- as.numeric(as.POSIXct(FD_Train$trans_date_trans_time))
FD_Test$trans_date_trans_time <- as.numeric(as.POSIXct(FD_Test$trans_date_trans_time))



#If there is a need to convert back then need to figure out the way to do that.
###FD_Train$trans_date_trans_time <- strptime(FD_Train$trans_date_trans_time, format = "%Y%m%d %H:%M:%s")
###FD_Train_trial2 <- as.numeric(FD_Train$trans_date_trans_time)

###FD_Train$trans_date_trans_time <- as.POSIXct(format(FD_Train$trans_date_trans_time))
###as.Date.POSIXct(FD_Train$trans_date_trans_time, origin = "1970-01-01 00:00")



#This will convert dob back to date.
###FD_Train$dob <- as.Date(FD_Train$dob, origin = "1970-01-01")


```


## Treatment for Imbalance Data using ROSE
```{r}
#install.packages("ROSE")
library(ROSE)

table(FD_Train$is_fraud)

FD_ROSE <- ROSE(formula = is_fraud~.,data = FD_Train, seed = 345)

table(FD_ROSE$data$is_fraud)

FD_Train_ROSE <- FD_ROSE$data


Reduced_FD_Train_ROSE <- subset(FD_Train_ROSE, select = c(2, 5, 6, 10, 11, 13, 14, 18, 20, 22, 23))
Reduced_FD_Test <- subset(FD_Test, select = c(2, 5, 6, 10, 11, 13, 14, 18, 20, 22, 23))


Reduced_FD_Train_ROSE3 <- subset(FD_Train_ROSE, select = c(2, 5, 6, 7, 9, 13, 14, 18, 20, 22, 23))

```


## Cross Validation???
```{r eval=FALSE, include=FALSE}
#install.packages("caret")
library(caret)

#specify cross-validation method
control <- trainControl(method = "cv", number = 2)

#fit a regression model and use k-fold CD to evaluate performance
mod <- train(is_fraud ~., merch_long, data = Reduced_FD_Train_ROSE, method = "lm", trControl = control)

# Unable to run, due to limited RAM size on PC.
```



# Modeling

## Classification

### Decision Tree
```{r}
#install.packages("rpart.plot")
library(rpart.plot)

#Train with model
fit_tree <- rpart(is_fraud~., data = Reduced_FD_Train_ROSE, method = "class")
rpart.plot(fit_tree, extra = 110)

# Prediction
predict_tree <- predict(fit_tree, FD_Test, type = "class")



```
## Testing merging of categorical variables
```{r eval=FALSE, include=FALSE}

Reduced_FD_Train_ROSE2 <- subset(FD_Train_ROSE, select = c(2, 4, 5, 6, 10, 11, 13, 14, 18, 20, 22, 23))

Reduced_FD_Train_ROSE2$M_cat_merch <- transform(Reduced_FD_Train_ROSE2, newVar = paste(category, merchant))

Reduced_FD_Train_ROSE2$M_cat_merch <- as.factor(Reduced_FD_Train_ROSE2$M_cat_merch)
```




### Random Forest
```{r eval=FALSE, include=FALSE}
#install.packages("randomForest")
library(randomForest)

#Train with model
fit_RF <- randomForest(is_fraud~., data = Reduced_FD_Train_ROSE, importance = TRUE, proximity = TRUE)

#Prediction
predict_RF <- predict(fit_RF, FD_Test, type)

```


### K-Nearest Neighbours
```{r}
#install.packages("class")
library(class)

# Use square root of nrow to figure out value for k.
nrow(Reduced_FD_Train_ROSE)

# Convert factor values to numeric.
Reduced_FD_Train_ROSE$category <- as.numeric(Reduced_FD_Train_ROSE$category)
Reduced_FD_Train_ROSE$street <- as.numeric(Reduced_FD_Train_ROSE$street)
Reduced_FD_Train_ROSE$city <- as.numeric(Reduced_FD_Train_ROSE$city)
Reduced_FD_Test$category <- as.numeric(Reduced_FD_Test$category)
Reduced_FD_Test$street <- as.numeric(Reduced_FD_Test$street)
Reduced_FD_Test$city <- as.numeric(Reduced_FD_Test$city)

# Train/prediction with model
fit_knn_1138 <- knn(train = Reduced_FD_Train_ROSE, test = Reduced_FD_Test, cl = Reduced_FD_Train_ROSE$is_fraud ,k = 50)
 #fit_knn_1139 <- knn(train = Reduced_FD_Train_ROSE, test = FD_Test, cl = Reduced_FD_Train_ROSE$is_fraud ,k = 1139)
#(is_fraud~., data = Reduced_FD_Train_ROSE, k = 1361)




```



## Regression
### Logistic Regression Binomial
```{r}

#fit_lg <- glm(is_fraud~., data = Reduced_FD_Train_ROSE, family = "binomial")
#install.packages("biglm")
#library(biglm)

#install.packages("gputools")
#library(gputools)




#fit_bigglm <- bigglm(is_fraud ~ trans_date_trans_time + category + amt + street + city + zip + lat + dob + unix_time + merch_long, data = Reduced_FD_Train_ROSE, family = "binomial")



#fit_bigglm_ffdf <- bigglm.data.frame(is_fraud ~ trans_date_trans_time + category + amt + street + city + zip + lat + dob + unix_time + merch_long, data = Reduced_FD_Train_ROSE, family = binomial(link = "logit"), chunksize = 51000)

library(caret)
#library(ggplot2)
#library(lattice)



logistic_model <- glm(is_fraud ~., family = binomial(), Reduced_FD_Train_ROSE3)

```


# Evaluation

## Confusion Matrix

### Decision Tree
```{r}
confusionMatrix_DS <- table(FD_Test$is_fraud, predict_tree)


```


### Random Forest
```{r}

```


### K-Nearest Neighbours
```{r}
library(caret)
confusionMatrix_knn <- confusionMatrix(table(fit_knn_1138, FD_Test$is_fraud))
confusionMatrix_knn
```


### Logistic Regression

## Accuracy, Recall, and Precision
### Accuracy, Recall, and Precision for Decision Tree
```{r}
library(caret)

confusionMatrix_DS
FD_Test$is_fraud <- as.factor(FD_Test$is_fraud)

#Accuracy
accuracy.meas(FD_Test$is_fraud, predict_tree)


# Recall
recall(FD_Test$is_fraud, predict_tree)


# Precision
precision(FD_Test$is_fraud, predict_tree)

print(confusionMatrix(data = FD_Test$is_fraud, reference = predict_tree))



```

